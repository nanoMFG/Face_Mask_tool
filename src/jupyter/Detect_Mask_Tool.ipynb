{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Mask Image\n",
    "\n",
    "This notebook uses the trained neural network to detect facemasks from user-supplied images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "requirejs.undef('filepicker');\n",
       "\n",
       "define('filepicker', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "\n",
       "    var FilePickerView = widgets.DOMWidgetView.extend({\n",
       "        render: function(){\n",
       "            this.file = document.createElement('input');\n",
       "            this.file.setAttribute('class', 'fileinput');\n",
       "            this.file.setAttribute('id', this.cid);\n",
       "            this.file.multiple = this.model.get('multiple');\n",
       "            this.file.required = true;\n",
       "            this.file.setAttribute('type', 'file');\n",
       "            this.file.setAttribute('style', 'display:none');\n",
       "\n",
       "            this.label = document.createElement('label');\n",
       "            this.label.setAttribute('for', this.cid);\n",
       "            this.label.setAttribute('style', 'border: 1px solid; border-radius: 5px; display: inline-block; padding: 6px 12px');\n",
       "\n",
       "            this.icon = document.createElement('i');\n",
       "            this.icon.setAttribute(\"class\", \"fa fa-upload\");\n",
       "\n",
       "            if (this.file.multiple) {\n",
       "                this.labelstr = \"  Upload Files\";\n",
       "            } else {\n",
       "                this.labelstr = \"  Upload File\";\n",
       "            }\n",
       "            this.label.innerHTML = this.labelstr;\n",
       "            this.label.prepend(this.icon);\n",
       "            this.el.appendChild(this.label);\n",
       "            this.el.appendChild(this.file);\n",
       "            this.listenTo(this.model, 'change:send', this._send_changed, this);\n",
       "            this.listenTo(this.model, 'change:reset', this._reset, this);\n",
       "            this.update();\n",
       "        },\n",
       "\n",
       "        events: {\n",
       "            // List of events and their handlers.\n",
       "            'change': 'handle_file_change'\n",
       "        },\n",
       "\n",
       "        _reset: function() {\n",
       "            this.label.innerHTML = this.labelstr;\n",
       "            this.label.prepend(this.icon);\n",
       "            this.file.removeAttribute(\"disabled\");\n",
       "        },\n",
       "\n",
       "        _send_changed: function() {\n",
       "            var that = this;\n",
       "            var send = this.model.get('send');\n",
       "            var fnum = send[0];\n",
       "            var offset = send[1];\n",
       "            var chunk_size=64*1024;\n",
       "            var reader;\n",
       "\n",
       "            if (fnum == -1) {\n",
       "                // ignore\n",
       "                return\n",
       "            }\n",
       "\n",
       "            if (offset == 0) {\n",
       "                this.model.set('sent', -1);\n",
       "                this.touch();\n",
       "            }\n",
       "\n",
       "            // console.log('send: ' + fnum + ' ' + offset);\n",
       "            function tob64( buffer ) {\n",
       "                var binary = '';\n",
       "                var bytes = new Uint8Array( buffer );\n",
       "                var len = bytes.byteLength;\n",
       "                for (var i = 0; i < len; i++) {\n",
       "                    binary += String.fromCharCode( bytes[ i ] );\n",
       "                }\n",
       "                return window.btoa( binary );\n",
       "            }\n",
       "\n",
       "            var reader_done = function (event) {\n",
       "                // chunk is finished.  Send to python\n",
       "                if (event.target.error == null) {\n",
       "                    var b64 = tob64(event.target.result);\n",
       "                    that.model.set('data', b64);\n",
       "                    that.model.set('sent', offset);\n",
       "                    that.touch();\n",
       "                } else {\n",
       "                    console.log(\"Read error: \" + event.target.error);\n",
       "                    that.model.set('data', '');\n",
       "                    that.model.set('sent', -2);\n",
       "                    that.touch();\n",
       "                }\n",
       "                that.touch();\n",
       "            }\n",
       "        \n",
       "            var chunk_reader = function (_offset, _f) {\n",
       "                // console.log('CR' + ' ' + _f + ' ' + _offset);\n",
       "                reader = new FileReader();\n",
       "                var chunk = _f.slice(_offset, chunk_size + _offset);            \n",
       "                reader.readAsArrayBuffer(chunk);\n",
       "                reader.onload = reader_done;\n",
       "            }\n",
       "    \n",
       "            // OK. request next chunk\n",
       "            chunk_reader(offset, this.files[fnum]);\n",
       "        },\n",
       "        \n",
       "        \n",
       "        handle_file_change: function(evt) {\n",
       "\n",
       "            var _files = evt.target.files;\n",
       "            var filenames = [];\n",
       "            var file_readers = [];\n",
       "            this.files = [];\n",
       "\n",
       "            for (var i = 0; i < _files.length; i++) {\n",
       "                var file = _files[i];\n",
       "                console.log(\"Filename: \" + file.name);\n",
       "                console.log(\"Type: \" + file.type);\n",
       "                console.log(\"Size: \" + file.size + \" bytes\");\n",
       "                this.files.push(file);\n",
       "                filenames.push([file.name, file.size]);\n",
       "            };\n",
       "            \n",
       "            // Set the filenames of the files.\n",
       "            this.model.set('filenames', filenames);\n",
       "            this.touch();\n",
       "\n",
       "            // update the label\n",
       "            if (filenames.length == 0) {\n",
       "                this.label.innerHTML = this.labelstr;\n",
       "                this.file.removeAttribute(\"disabled\");\n",
       "            } else if (filenames.length == 1) {\n",
       "                this.label.innerHTML = \"  \" + filenames[0][0];\n",
       "                this.file.setAttribute('disabled', 'true');\n",
       "            } else {\n",
       "                this.label.innerHTML = \"  \" + filenames.length + \" files selected\";\n",
       "                this.file.setAttribute('disabled', 'true');           \n",
       "            };\n",
       "            this.label.prepend(this.icon);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    // Register the FilePickerView with the widget manager.\n",
       "    return {\n",
       "        FilePickerView: FilePickerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODIFY ALL COMMENTS IN THIS NOTEBOOK SO THAT THEY APPEAR AS HEADINGS ABOVE THE CELLS, AS IN THE ABOVE. \n",
    "\n",
    "# USAGE\n",
    "# python detect_mask_image.py --image examples/example_01.png\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import hublib\n",
    "from hublib.ui import FileUpload, Download\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY THIS SO THAT: \n",
    "# 1. The user can supply their own image via direct upload or pull an example from the example directory  \n",
    "# 2. The user can choose either the default model or one that they trained themselves.  \n",
    "# 3. Let the user modify the confidence level from 0.5 \n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", \n",
    "\tdefault=\"examples/example-01.png\",\n",
    "\thelp=\"path to input image\")\n",
    "ap.add_argument(\"-f\", \"--face\", type=str,\n",
    "\tdefault=\"face_detector\",\n",
    "\thelp=\"path to face detector model directory\")\n",
    "ap.add_argument(\"-m\", \"--model\", type=str,\n",
    "\tdefault=\"mask_detector.model\",\n",
    "\thelp=\"path to trained face mask detector model\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
    "\thelp=\"minimum probability to filter weak detections\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499edd5455e448e49a1d31f36ba75f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<p data-toggle=\"popover\" title=\"< Description >\">Upload Image</p>', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmpdir/Example-06.jpg' -> 'data/raw/Example-06.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/UIUC_Offline/Tool/FaceMask/face_mask/lib/python3.8/site-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36m_handle_msg\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'buffer_paths'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                     \u001b[0m_put_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'buffer_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'buffers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;31m# Handle a state request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/UIUC_Offline/Tool/FaceMask/face_mask/lib/python3.8/site-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mset_state\u001b[0;34m(self, sync_data)\u001b[0m\n\u001b[1;32m    543\u001b[0m                     from_json = self.trait_metadata(name, 'from_json',\n\u001b[1;32m    544\u001b[0m                                                     self._trait_from_json)\n\u001b[0;32m--> 545\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msync_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/UIUC_Offline/Tool/FaceMask/face_mask/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mhold_trait_notifications\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchanges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/UIUC_Offline/Tool/FaceMask/face_mask/lib/python3.8/site-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0;31m# Send new state to front-end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWidget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/UIUC_Offline/Tool/FaceMask/face_mask/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_notifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/UIUC_Offline/Tool/FaceMask/face_mask/lib/python3.8/site-packages/hublib/ui/upload.py\u001b[0m in \u001b[0;36m_data_received\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0;31m# done with all downloads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fe117fdd8ddc>\u001b[0m in \u001b[0;36mmycb\u001b[0;34m(w, fnames)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfilelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/raw/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmpdir/Example-06.jpg' -> 'data/raw/Example-06.jpg'"
     ]
    }
   ],
   "source": [
    "global filelist\n",
    "filelist = []\n",
    "\n",
    "def mycb(w,fnames):\n",
    "    global fnm\n",
    "    fnm=fnames[0]\n",
    "    fbase = os.path.basename(fnm)\n",
    "    os.makedirs('data/' + os.path.splitext(fbase)[0])\n",
    "    filelist.append(fbase)\n",
    "    os.rename(fnm, 'data/raw/' + fbase)\n",
    "    w.reset()\n",
    "\n",
    "f = FileUpload(\"Upload Image\", \n",
    "               \"< Description >\",\n",
    "               cb=mycb,\n",
    "               maxsize=10000000)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/dnn/src/caffe/caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"/Users/aagam2/Library/Jupyter/runtime/kernel-460a5b00-8bb4-4982-80f6-41ab5a8c5559.json/deploy.prototxt\" in function 'ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7157ba0e3833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m weightsPath = os.path.sep.join([args[\"face\"],\n\u001b[1;32m      8\u001b[0m \t\"res10_300x300_ssd_iter_140000.caffemodel\"])\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprototxtPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# load the face mask detector model from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/dnn/src/caffe/caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"/Users/aagam2/Library/Jupyter/runtime/kernel-460a5b00-8bb4-4982-80f6-41ab5a8c5559.json/deploy.prototxt\" in function 'ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "# MODIFY THIS PART SO THAT \n",
    "# 1. Provide the user to download the resulting image. \n",
    "\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([args[\"face\"], \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([args[\"face\"],\n",
    "\t\"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "# load the face mask detector model from disk\n",
    "print(\"[INFO] loading face mask detector model...\")\n",
    "model = load_model(args[\"model\"])\n",
    "\n",
    "# load the input image from disk, clone it, and grab the image spatial\n",
    "# dimensions\n",
    "image = cv2.imread(args[\"image\"])\n",
    "orig = image.copy()\n",
    "(h, w) = image.shape[:2]\n",
    "\n",
    "# construct a blob from the image\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
    "\t(104.0, 177.0, 123.0))\n",
    "\n",
    "# pass the blob through the network and obtain the face detections\n",
    "print(\"[INFO] computing face detections...\")\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "\n",
    "# loop over the detections\n",
    "for i in range(0, detections.shape[2]):\n",
    "\t# extract the confidence (i.e., probability) associated with\n",
    "\t# the detection\n",
    "\tconfidence = detections[0, 0, i, 2]\n",
    "\n",
    "\t# filter out weak detections by ensuring the confidence is\n",
    "\t# greater than the minimum confidence\n",
    "\tif confidence > args[\"confidence\"]:\n",
    "\t\t# compute the (x, y)-coordinates of the bounding box for\n",
    "\t\t# the object\n",
    "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\t\t# ensure the bounding boxes fall within the dimensions of\n",
    "\t\t# the frame\n",
    "\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
    "\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "\t\t# extract the face ROI, convert it from BGR to RGB channel\n",
    "\t\t# ordering, resize it to 224x224, and preprocess it\n",
    "\t\tface = image[startY:endY, startX:endX]\n",
    "\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\t\tface = cv2.resize(face, (224, 224))\n",
    "\t\tface = img_to_array(face)\n",
    "\t\tface = preprocess_input(face)\n",
    "\t\tface = np.expand_dims(face, axis=0)\n",
    "\n",
    "\t\t# pass the face through the model to determine if the face\n",
    "\t\t# has a mask or not\n",
    "\t\t(mask, withoutMask) = model.predict(face)[0]\n",
    "\n",
    "\t\t# determine the class label and color we'll use to draw\n",
    "\t\t# the bounding box and text\n",
    "\t\tlabel = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "\t\t# include the probability in the label\n",
    "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "\t\t# display the label and bounding box rectangle on the output\n",
    "\t\t# frame\n",
    "\t\tcv2.putText(image, label, (startX, startY - 10),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "\t\tcv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
